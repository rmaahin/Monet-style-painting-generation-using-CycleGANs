# Monet-style-painting-generation-using-CycleGANs
CycleGAN is a method for performing image-to-image translation as indicated by [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593). This work is inspired by [AK Nain's work](https://keras.io/examples/generative/cyclegan/) and the main idea here is to convert images generated by a camera to a monet style painting.

## Requirements
This code was written in Python (3.9.5) and Tensorflow (2.5.0).

## How to run

The dataset was provided as part of the Kaggle Competition, [I'm Something of a Painter Myself](https://www.kaggle.com/c/gan-getting-started). You can download the dataset by simply entering the competition.

* To train the model:
  Run [Train.py](https://github.com/rmaahin/Monet-style-painting-generation-using-CycleGANs/blob/main/Train.py) 
  
Training takes approximately 7 mins for one epoch on Nvidia GTX 1060 max-q. I suggest you use google colab since the dataset is quite small.

* To test the model:
  Train.py has a segment dedicated to testing random images from the dataset. It converts random images from photos and converts them to monet style paintings.
